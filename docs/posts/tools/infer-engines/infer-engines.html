<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-01-24">

<title>Linghao Wang - Model Deployment and Compression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Linghao Wang</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../talks.html">
 <span class="menu-text">Talks</span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#model-deployment-tensorrt-triton-ncnn" id="toc-model-deployment-tensorrt-triton-ncnn" class="nav-link active" data-scroll-target="#model-deployment-tensorrt-triton-ncnn"><span class="toc-section-number">1</span>  Model Deployment: TensorRT, Triton, NCNN</a>
  <ul class="collapse">
  <li><a href="#why-tensorrt" id="toc-why-tensorrt" class="nav-link" data-scroll-target="#why-tensorrt"><span class="toc-section-number">1.1</span>  Why TensorRT?</a></li>
  <li><a href="#why-triton-server" id="toc-why-triton-server" class="nav-link" data-scroll-target="#why-triton-server"><span class="toc-section-number">1.2</span>  Why Triton Server?</a></li>
  <li><a href="#tensorrttriton-workflow" id="toc-tensorrttriton-workflow" class="nav-link" data-scroll-target="#tensorrttriton-workflow"><span class="toc-section-number">1.3</span>  TensorRT+Triton Workflow</a></li>
  <li><a href="#ncnn-workflow" id="toc-ncnn-workflow" class="nav-link" data-scroll-target="#ncnn-workflow"><span class="toc-section-number">1.4</span>  NCNN Workflow</a></li>
  </ul></li>
  <li><a href="#model-compression-pruning-distillation-quantization-sparsity-nas" id="toc-model-compression-pruning-distillation-quantization-sparsity-nas" class="nav-link" data-scroll-target="#model-compression-pruning-distillation-quantization-sparsity-nas"><span class="toc-section-number">2</span>  Model Compression: Pruning, Distillation, Quantization, Sparsity, NAS</a>
  <ul class="collapse">
  <li><a href="#pruning" id="toc-pruning" class="nav-link" data-scroll-target="#pruning"><span class="toc-section-number">2.1</span>  Pruning</a></li>
  <li><a href="#distillation" id="toc-distillation" class="nav-link" data-scroll-target="#distillation"><span class="toc-section-number">2.2</span>  Distillation</a></li>
  <li><a href="#quantization" id="toc-quantization" class="nav-link" data-scroll-target="#quantization"><span class="toc-section-number">2.3</span>  Quantization</a></li>
  <li><a href="#sparsity" id="toc-sparsity" class="nav-link" data-scroll-target="#sparsity"><span class="toc-section-number">2.4</span>  Sparsity</a></li>
  <li><a href="#neural-architecture-search-nas" id="toc-neural-architecture-search-nas" class="nav-link" data-scroll-target="#neural-architecture-search-nas"><span class="toc-section-number">2.5</span>  Neural Architecture Search (NAS)</a></li>
  </ul></li>
  <li><a href="#reference" id="toc-reference" class="nav-link" data-scroll-target="#reference"><span class="toc-section-number">3</span>  Reference</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Model Deployment and Compression</h1>
  <div class="quarto-categories">
    <div class="quarto-category">tools</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 24, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="{fig-vis}">
<p><img src="MDLBench.png" class="img-fluid" style="width:100.0%"></p>
</div>
<!--
# Tool List for Model Deployment

## DL Framework List for Server
- TensorRT: Nvidia, for GPU
- OpenVino: Intel, for CPU
- ONNX: Microsoft, Amazon, and others

## DL Framework List for Mobile 
- ncnn/TNN: Tencent
- MNN: Alibaba
- MACE: Xiaomi
- Tengine: Open AI Lab
- Paddle-Lite: Baidu

## DL Inference Server
- Triton: Nvidia

## DL Deployment Tool
- FastDeploy: Nvidia
-->
<section id="model-deployment-tensorrt-triton-ncnn" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="model-deployment-tensorrt-triton-ncnn"><span class="header-section-number">1</span> Model Deployment: TensorRT, Triton, NCNN</h2>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Take away
</div>
</div>
<div class="callout-body-container callout-body">
<p>Start with Nvidia TensorRT and Triton for deployment on server, then learn NCNN for mobile deployment.</p>
</div>
</div>
<section id="why-tensorrt" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="why-tensorrt"><span class="header-section-number">1.1</span> Why TensorRT?</h3>
<p>NVIDIA TensorRT is a deep learning platform that optimizes neural network models and speeds up inference across GPU-accelerated platforms running in the data center and embedded devices.</p>
<div class="{fig-vis}">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="TensorRT.jpg" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Same model, 4x Faster &amp; 6x Smaller with TensorRT-FP16</figcaption><p></p>
</figure>
</div>
</div>
</section>
<section id="why-triton-server" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="why-triton-server"><span class="header-section-number">1.2</span> Why Triton Server?</h3>
<p>Triton enables teams to deploy any AI model from multiple deep learning and machine learning frameworks, including TensorRT, TensorFlow, PyTorch, ONNX.</p>
<div class="{fig-vis}">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Triton.jpg" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">4x QPS with TensorRT+Triton</figcaption><p></p>
</figure>
</div>
</div>
</section>
<section id="tensorrttriton-workflow" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="tensorrttriton-workflow"><span class="header-section-number">1.3</span> TensorRT+Triton Workflow</h3>
<div class="{fig-vis}">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="workflow.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Overall workflow for optimizing a model with TensorRT and serving with NVIDIA Triton</figcaption><p></p>
</figure>
</div>
</div>
</section>
<section id="ncnn-workflow" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="ncnn-workflow"><span class="header-section-number">1.4</span> <a href="https://github.com/Tencent/ncnn">NCNN</a> Workflow</h3>
</section>
</section>
<section id="model-compression-pruning-distillation-quantization-sparsity-nas" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="model-compression-pruning-distillation-quantization-sparsity-nas"><span class="header-section-number">2</span> Model Compression: Pruning, Distillation, Quantization, Sparsity, NAS</h2>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Take away
</div>
</div>
<div class="callout-body-container callout-body">
<p>Start with pruning. Choose any other method depending on (1) task requirements and (2) hardware.</p>
</div>
</div>
<section id="pruning" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="pruning"><span class="header-section-number">2.1</span> Pruning</h3>
<p>Good generalization.</p>
<p><a href="https://nni.readthedocs.io/zh/stable/compression/overview.html">Check out an Microsoft Pytorch-based tool: Neural Network Intelligence (NNI).</a></p>
</section>
<section id="distillation" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="distillation"><span class="header-section-number">2.2</span> Distillation</h3>
<p>A large model T teaches a small model S and transfer S’s knowledge. Distillation is suitable for complicated tasks and small models.</p>
<p>It can be classified by different methods:</p>
<ul>
<li>Response-based</li>
<li>Feature-based</li>
<li>Relation-based</li>
</ul>
<p>or different strategies:</p>
<ul>
<li>online distillation</li>
<li>offline distillation</li>
<li>self distillation</li>
</ul>
<p>or different distillation algorithms:</p>
<ul>
<li>adversarial distillation</li>
<li>multi-teacher distillation</li>
<li>cross-modal distillation</li>
<li>graph-based distillation</li>
<li>attention-based distillation</li>
<li>data-free distillation</li>
<li>quatized Distillation</li>
<li>lifelong distillation</li>
<li>nas distillation</li>
</ul>
<div class="{fig-vis}">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="distillation.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">The procedure.</figcaption><p></p>
</figure>
</div>
</div>
</section>
<section id="quantization" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="quantization"><span class="header-section-number">2.3</span> Quantization</h3>
<p>High requirements for specific hardware, e.g., Intel cpu.</p>
<p><a href="https://nni.readthedocs.io/zh/stable/compression/overview.html">Check out an Microsoft Pytorch-based tool: Neural Network Intelligence (NNI).</a></p>
</section>
<section id="sparsity" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="sparsity"><span class="header-section-number">2.4</span> Sparsity</h3>
<p>You can make some tensors to be 0, but depends on specific hardwares, e.g., 30xx GPU. <a href="https://github.com/NVIDIA/apex/tree/082f999a6e18a3d02306e27482cc7486dab71a50/apex/contrib/sparsity">Check out an Nvidia Pytorch-based tool: Automated SParsity (ASP).</a></p>
</section>
<section id="neural-architecture-search-nas" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="neural-architecture-search-nas"><span class="header-section-number">2.5</span> Neural Architecture Search (NAS)</h3>
<p>You can modify the DARTS model space and tasks to deploy NAS, mostly for models like MobileNet series. For example, you can use NAS to search the backbone, channel, depth, kernel size, resolution and other hyperparams of the model, but NAS requires super computing power because of the large searching space. This requirement welcomes big companies like Google and Facebook, but stops small labs and companies from NAS’s research. <a href="https://nni.readthedocs.io/zh/stable/tutorials/hello_nas.html">Check out an Microsoft Pytorch-based tool: Neural Network Intelligence (NNI).</a></p>
</section>
</section>
<section id="reference" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="reference"><span class="header-section-number">3</span> Reference</h2>
<ul>
<li><a href="https://blog.advance.ai/blog/accelerating-ai-deep-learning-models">Accelerating AI/Deep learning models using tensorRT &amp; triton inference</a></li>
<li><a href="https://developer.nvidia.com/blog/optimizing-and-serving-models-with-nvidia-tensorrt-and-nvidia-triton/">Optimizing and Serving Models with NVIDIA TensorRT and NVIDIA Triton</a></li>
<li><a href="https://arxiv.org/pdf/2202.06512.pdf">A Comprehensive Benchmark of Deep Learning Libraries on Mobile Devices (WWW 2022)</a></li>
<li><a href="https://www.mdnice.com/writing/3efb55c789e94c5599eb1a0d1bf05b82">训练好的深度学习模型是怎么部署的？</a> <a href="https://juejin.cn/post/7133391555854860318">边缘计算 | 在移动设备上部署深度学习模型的思路与注意点</a> <a href="https://oldpan.me/archives/ai-deploy-study-road-1">老潘的AI部署以及工业落地学习之路</a></li>
<li><a href="https://www.zhihu.com/question/357967490/answer/911735881">在实际工程应用中,剪枝, 蒸馏等模型压缩方法中的具体哪个算法部署简单且有效?</a></li>
<li><a href="https://github.com/Syencil/mobile-yolov5-pruning-distillation">mobilev2-yolov5s剪枝、蒸馏，支持ncnn，tensorRT部署。ultra-light but better performence！</a></li>
<li><a href="https://github.com/HobbitLong/RepDistiller">[ICLR 2020] Contrastive Representation Distillation (CRD), and benchmark of recent knowledge distillation methods</a></li>
<li><a href="https://www.zhihu.com/question/518810217/answer/2367413413">2022 年神经架构搜索的发展状况如何?</a></li>
<li><a href="https://blog.salesforceairesearch.com/benchmarking-tensorrt-inference-server/">Benchmarking Triton (TensorRT) Inference Server for Transformer Models</a></li>
<li><a href="https://www.reddit.com/r/MachineLearning/comments/i3knzb/d_what_pytorchs_model_serving_framework_are_you/">https://www.reddit.com/r/MachineLearning/comments/i3knzb/d_what_pytorchs_model_serving_framework_are_you/</a></li>
<li><a href="https://clear.ml/blog/increase-huggingface-triton-throughput-by-193/">How to Accelerate HuggingFace Throughput by 193%</a></li>
<li><a href="https://towardsdatascience.com/hugging-face-transformer-inference-under-1-millisecond-latency-e1be0057a51c">Hugging Face Transformer Inference Under 1 Millisecond Latency</a></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'alternate';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp(/https:\/\/waterking\.cc/);
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
    var links = window.document.querySelectorAll('a:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2022 © Linghao Wang</div>   
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/linghao-wang/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Waterkin">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>